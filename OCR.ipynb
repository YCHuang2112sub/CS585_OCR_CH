{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference: \n",
    "\n",
    "[trocr-chinese](https://github.com/topics/chinese-character-recognition)\n",
    "\n",
    "[chineseocr](https://github.com/chineseocr/chineseocr)\n",
    "\n",
    "\n",
    "[PaddleOCR zhihu](https://zhuanlan.zhihu.com/p/342425028)\n",
    "\n",
    "[PaddleOCR github](https://github.com/PaddlePaddle/PaddleOCR)\n",
    "\n",
    "\n",
    "[EAST text localization 2017 OpenCV](https://zhuanlan.zhihu.com/p/64737915)\n",
    "\n",
    "# Tesseract-ORC\n",
    "\n",
    "[Tesseract download and install](https://github.com/UB-Mannheim/tesseract/wiki)\n",
    "\n",
    "[python tesseract stackoverflow getting BoundingBox](https://stackoverflow.com/questions/20831612/getting-the-bounding-box-of-the-recognized-words-using-python-tesseract)\n",
    "\n",
    "[python tesseract ithome](https://ithelp.ithome.com.tw/articles/10227263)\n",
    "\n",
    "# Dataset:\n",
    "\n",
    "[CTW dataset](https://ctwdataset.github.io/tutorial/1-basics.html)\n",
    "\n",
    "[MTHv2 dataset](https://github.com/HCIILAB/MTHv2_Datasets_Release)\n",
    "\n",
    "[TKH_MTH_Datasets_Release](https://github.com/HCIILAB/TKH_MTH_Datasets_Release)\n",
    "\n",
    "[Handwriting OCR Data of Japanese and Korean](https://www.kaggle.com/datasets/nexdatafrank/handwriting-ocr-data-of-japanese-and-korean?resource=download)\n",
    "\n",
    "# YOLO-v7 \n",
    "\n",
    "[yolov7 github](https://github.com/WongKinYiu/yolov7/tree/main)\n",
    "\n",
    "[yolov7 training](https://medium.com/@happy6140/%E5%AF%A6%E4%BD%9Cyolo-v7-%E8%A8%93%E7%B7%B4%E8%87%AA%E5%B7%B1%E7%9A%84%E8%B3%87%E6%96%99%E9%9B%86-cffa1b13f681)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "from PIL import Image\n",
    "img_path = \"./dataset/TKHMTH2200/MTH1000/images/01-V001P000C.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# [image_to_data](https://github.com/madmaze/pytesseract/blob/master/pytesseract/pytesseract.py)\n",
    "d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "n_boxes = len(d['level'])\n",
    "for i in range(n_boxes):\n",
    "    (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-openai-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
